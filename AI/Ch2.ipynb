{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 신경망과의 첫 만남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST 데이터셋 로드\n",
    "from keras.datasets import mnist\n",
    "\n",
    "## train_*: 훈련 세트(training set), test_*: 테스트 세트(test set)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape ## (60000, 28, 28) => 6만개의 이미지, 각 이미지는 28x28 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels) ## 60000 => 6만개의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels ## 훈련 세트의 레이블 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape ## (10000, 28, 28) => 1만개의 이미지, 각 이미지는 28x28 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels) ## 10000 => 1만개의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels ## 테스트 세트의 레이블 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 신경망 구조\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'), ## 512개의 유닛\n",
    "    layers.Dense(10, activation='softmax') ## 10개의 확률 점수가 들어있는 배열을 반환하는 소프트맥스 층\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 신경망 컴파일\n",
    "model.compile(optimizer='rmsprop', ## 옵티마이저: rmsprop\n",
    "                loss='sparse_categorical_crossentropy', ## 손실 함수: sparse_categorical_crossentropy\n",
    "                metrics=['accuracy']) ## 측정 지표: 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 데이터 준비 => 0~255 사이의 값인 uint8 타입의 (60000, 28, 28) 크기를 가진 배열을 0과 1 사이의 값인 float32 타입의 (60000, 28 * 28) 크기로 변환\n",
    "train_images = train_images.reshape((60000, 28 * 28)) ## 2차원 배열을 1차원 배열로 변환\n",
    "train_images = train_images.astype('float32') / 255 ## 정규화\n",
    "test_images = test_images.reshape((10000, 28 * 28)) ## 2차원 배열을 1차원 배열로 변환\n",
    "test_images = test_images.astype('float32') / 255 ## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Catetorically encode the labels\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "## One-hot encoding\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.4423\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1161\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0733\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0493\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30c100d10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 신경망 모델 훈련\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128) ## 5번의 에포크 동안 훈련, 미니 배치 크기는 128\n",
    "## 훈련하는 동안 손실과 정확도 지표를 출력  \n",
    "## accuracy: 훈련 데이터에 대한 정확도, loss: 훈련 데이터에 대한 손실\n",
    "## epochs(에포크): 전체 훈련 데이터에 수행하는 각 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.1563151e-07, 2.8172980e-09, 3.9428760e-05, 1.2424696e-04,\n",
       "       1.9504869e-10, 1.0206078e-07, 2.8430114e-11, 9.9982166e-01,\n",
       "       4.2598740e-06, 9.6341118e-06], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델을 사용하여 예측 만들기\n",
    "test_digits = test_images[0:10] ## 테스트 데이터에서 숫자 이미지를 선택\n",
    "predictions = model.predict(test_digits) ## 이미지에 대한 예측을 만듦\n",
    "predictions[0] ## 첫 번째 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax() ## 가장 높은 확률을 가진 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99982166"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7] ## 7에 대한 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0] ## 실제 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9759 - loss: 0.0786\n",
      "테스트 정확도: 0.9794999957084656\n"
     ]
    }
   ],
   "source": [
    "## 새로운 데이터에서 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels) ## 테스트 데이터에 대한 정확도 계산\n",
    "print(f\"테스트 정확도: {test_acc}\") ## 테스트 정확도 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 신경망을 위한 데이터 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sclar tensor (0차원(0D) 텐서)\n",
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim ## 0차원 텐서의 축 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector tensor (1차원(1D) 텐서)\n",
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim ## 1차원 텐서의 축 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix tensor (2차원(2D) 텐서)\n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim ## 2차원 텐서의 축 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D tensor\n",
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim ## 3차원 텐서의 축 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "## MNIST 데이터셋으로 텐서의 핵심 속성 확인\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.ndim) ## 3차원 텐서\n",
    "print(train_images.shape) ## (60000, 28, 28)\n",
    "print(train_images.dtype) ## uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 5번째 이미지 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 넘파이로 텐서 조작\n",
    "my_slice = train_images[10:100] ## 10에서 100번째까지 숫자를 선택\n",
    "my_slice.shape ## (90, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :] ## 위와 동일\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28] ## 위와 동일\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:] ## 모든 이미지에서 가운데 14x14 픽셀 선택\n",
    "my_slice.shape ## (60000, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7] ## 위와 동일, 음수 인덱스도 사용가능\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 배치 데이터\n",
    "## MNIST 숫자 데이터에서 크기가 128인 배치를 만들기\n",
    "batch = train_images[:128] ## 첫 번째 배치\n",
    "batch = train_images[128:256] ## 두 번째 배치\n",
    "\n",
    "n=3\n",
    "batch = train_images[128 * n:128 * (n + 1)] ## n번째 배치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. 신경망의 톱니바퀴: 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense_2, built=False>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 텐서 덧셈 연산\n",
    "keras.layers.Dense(512, activation='relu') ## Dense 층 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원소별 연산\n",
    "## relu 연산\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 ## x는 2D 넘파이 배열\n",
    "    \n",
    "    x = x.copy() ## 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 덧셈 연산\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2 ## x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy() ## 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 곱셈 연산\n",
    "def naive_mul(x, y):\n",
    "    assert len(x.shape) == 2 ## x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy() ## 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] *= y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 뻴셈 연산\n",
    "def naive_sub(x, y):\n",
    "    assert len(x.shape) == 2 ## x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy() ## 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] -= y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 브로드캐스팅\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((64, 3, 32, 10)) ## x는 (64, 3, 32, 10) 크기의 랜덤 텐서\n",
    "y = np.random.random((32, 10)) ## y는 (32, 10) 크기의 랜덤 텐서\n",
    "z = np.maximum(x, y) ## 출력 z의 크기는 x와 동일\n",
    "z.ndim ## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 텐서 크기 변환\n",
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "x.shape ## (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 행렬의 전치\n",
    "x = np.zeros((300, 20)) ## 모두 0으로 채워진 (300, 20) 크기의 행렬\n",
    "x = np.transpose(x)\n",
    "x.shape ## (20, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
